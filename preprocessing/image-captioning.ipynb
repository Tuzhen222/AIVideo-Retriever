{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92ef94b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T12:25:03.415302Z",
     "iopub.status.busy": "2025-12-07T12:25:03.414919Z",
     "iopub.status.idle": "2025-12-07T12:25:03.422849Z",
     "shell.execute_reply": "2025-12-07T12:25:03.422056Z"
    },
    "papermill": {
     "duration": 0.012946,
     "end_time": "2025-12-07T12:25:03.424254",
     "exception": false,
     "start_time": "2025-12-07T12:25:03.411308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# -------- C·∫§U H√åNH CH·∫†Y L·∫†I CHO C√ÅC PART B·ªä THI·∫æU --------\n",
    "\n",
    "# S·ªë part ban ƒë·∫ßu khi chia full dataset\n",
    "ORIGINAL_NUM_PARTS = 53\n",
    "\n",
    "# Nh·ªØng part ƒë√£ b·ªã ng·∫Øt ·ªü l·∫ßn ch·∫°y ƒë·∫ßu\n",
    "MISSING_PARTS = [8, 15, 17, 39, 45, 46]\n",
    "\n",
    "# Chia l·∫°i to√†n b·ªô t·∫≠p \"thi·∫øu\" th√†nh bao nhi√™u part m·ªõi\n",
    "NUM_PARTS = 12              # ·ªü ƒë√¢y l√† 12\n",
    "\n",
    "# M·ªói l·∫ßn submit notebook tr√™n Kaggle, ƒë·ªïi NUM_ID = 1..12\n",
    "NUM_ID = 8                  # <-- s·ª≠a s·ªë n√†y khi ch·∫°y t·ª´ng part\n",
    "\n",
    "BATCH_SIZE = 32             # s·ªë ·∫£nh x·ª≠ l√Ω ƒë·ªìng th·ªùi tr√™n m·ªói GPU\n",
    "\n",
    "# ƒê∆∞·ªùng d·∫´n ƒë·∫øn file index (gi·ªØ nguy√™n)\n",
    "INDEX_FILE = \"/kaggle/input/irkeyframeindex/keyframe_index_kaggle.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9547d4be",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-07T12:25:03.429606Z",
     "iopub.status.busy": "2025-12-07T12:25:03.429322Z",
     "iopub.status.idle": "2025-12-07T12:25:19.266897Z",
     "shell.execute_reply": "2025-12-07T12:25:19.265997Z"
    },
    "papermill": {
     "duration": 15.842187,
     "end_time": "2025-12-07T12:25:19.268510",
     "exception": false,
     "start_time": "2025-12-07T12:25:03.426323",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import gc\n",
    "import torch\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForCausalLM\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from threading import Lock\n",
    "\n",
    "OUTPUT_DIR = \"/kaggle/working/captions_per_part\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "MODEL_NAME = \"vikhyatk/moondream2\"\n",
    "REVISION = \"2025-06-21\"\n",
    "\n",
    "# Lock ƒë·ªÉ ƒë·ªìng b·ªô khi ghi k·∫øt qu·∫£\n",
    "caption_lock = Lock()\n",
    "\n",
    "\n",
    "def load_model(device):\n",
    "    print(f\"üì• Loading Moondream2 model on {device}...\")\n",
    "    device_id = device.index if hasattr(device, 'index') else int(str(device).split(':')[-1])\n",
    "    model = AutoModelForCausalLM.from_pretrained(\n",
    "        MODEL_NAME,\n",
    "        revision=REVISION,\n",
    "        trust_remote_code=True,\n",
    "        device_map={\"\": device_id}\n",
    "    )\n",
    "    print(f\"‚úÖ Model loaded on {device}\")\n",
    "    return model\n",
    "\n",
    "\n",
    "def caption_image(model, image_path):\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        result = model.caption(image, length=\"normal\")\n",
    "        return result[\"caption\"]\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error captioning {image_path}: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def load_index_file(index_path):\n",
    "    \"\"\"Load all images from index file as a flat list\"\"\"\n",
    "    with open(index_path, 'r') as f:\n",
    "        index_data = json.load(f)\n",
    "    \n",
    "    # Convert to list of (idx, img_path) tuples\n",
    "    all_images = [(int(idx), img_path) for idx, img_path in index_data.items()]\n",
    "    all_images.sort(key=lambda x: x[0])  # Sort by index\n",
    "    \n",
    "    return all_images\n",
    "\n",
    "\n",
    "def split_dataset(all_images, num_parts, part_id):\n",
    "    \"\"\"Split dataset into parts and return the selected part\"\"\"\n",
    "    total_images = len(all_images)\n",
    "    \n",
    "    # Calculate partition boundaries\n",
    "    images_per_part = total_images // num_parts\n",
    "    remainder = total_images % num_parts\n",
    "    \n",
    "    # Calculate start and end indices for this part\n",
    "    if part_id <= remainder:\n",
    "        start_idx = (part_id - 1) * (images_per_part + 1)\n",
    "        end_idx = start_idx + images_per_part + 1\n",
    "    else:\n",
    "        start_idx = remainder * (images_per_part + 1) + (part_id - remainder - 1) * images_per_part\n",
    "        end_idx = start_idx + images_per_part\n",
    "    \n",
    "    selected_images = all_images[start_idx:end_idx]\n",
    "    \n",
    "    print(f\"üìä Total images: {total_images}\")\n",
    "    print(f\"üì¶ Part {part_id}/{num_parts}: Processing images {start_idx+1} to {end_idx}\")\n",
    "    print(f\"üñºÔ∏è  Number of images in this part: {len(selected_images)}\")\n",
    "    \n",
    "    return selected_images\n",
    "\n",
    "\n",
    "def process_batch_on_gpu(model, image_batch, gpu_id, all_captions):\n",
    "    \"\"\"Process a batch of images on a specific GPU\"\"\"\n",
    "    batch_captions = {}\n",
    "    \n",
    "    for idx, img_path in image_batch:\n",
    "        caption = caption_image(model, img_path)\n",
    "        if caption:\n",
    "            batch_captions[str(idx)] = caption\n",
    "    \n",
    "    # Thread-safe update of shared results\n",
    "    with caption_lock:\n",
    "        all_captions.update(batch_captions)\n",
    "    \n",
    "    return len(batch_captions), gpu_id\n",
    "\n",
    "\n",
    "def main():\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"üöÄ Starting captioning on {num_gpus} GPU(s)\")\n",
    "    print(f\"üìã Original dataset was split into {ORIGINAL_NUM_PARTS} parts\")\n",
    "    print(f\"üìã Missing original parts: {MISSING_PARTS}\")\n",
    "    print(f\"üìã New subset partition: Part {NUM_ID}/{NUM_PARTS}\")\n",
    "    print(f\"üì¶ Batch size: {BATCH_SIZE} images per GPU\")\n",
    "    \n",
    "    # 1. Load full index\n",
    "    print(f\"\\nüìÇ Loading index file: {INDEX_FILE}\")\n",
    "    all_images = load_index_file(INDEX_FILE)\n",
    "    \n",
    "    # 2. Gom ·∫£nh t·ª´ 6 part c≈© b·ªã thi·∫øu th√†nh m·ªôt t·∫≠p m·ªõi\n",
    "    print(f\"\\nüß© Collecting images from missing parts...\")\n",
    "    missing_images = []\n",
    "    for missing_id in MISSING_PARTS:\n",
    "        print(f\"\\nüîç Collecting images from original part {missing_id}/{ORIGINAL_NUM_PARTS}...\")\n",
    "        part_images = split_dataset(all_images, ORIGINAL_NUM_PARTS, missing_id)\n",
    "        print(f\"   ‚ûï Added {len(part_images)} images\")\n",
    "        missing_images.extend(part_images)\n",
    "    \n",
    "    print(f\"\\nüß© Total images in missing subset: {len(missing_images)}\")\n",
    "    print(f\"üìã Re-splitting missing subset into {NUM_PARTS} new parts...\")\n",
    "    \n",
    "    # 3. Chia l·∫°i t·∫≠p \"thi·∫øu\" th√†nh 12 ph·∫ßn m·ªõi v√† l·∫•y part ƒëang c·∫ßn ch·∫°y\n",
    "    selected_images = split_dataset(missing_images, NUM_PARTS, NUM_ID)\n",
    "    \n",
    "    if not selected_images:\n",
    "        print(\"‚ùå No images found in this partition!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nüñºÔ∏è  Processing {len(selected_images)} images in this partition\")\n",
    "    \n",
    "    # 4. Load model(s)\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üì• Loading model(s)...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    models = []\n",
    "    for gpu_id in range(num_gpus):\n",
    "        device = torch.device(f\"cuda:{gpu_id}\")\n",
    "        model = load_model(device)\n",
    "        models.append(model)\n",
    "    \n",
    "    all_captions = {}\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üîÑ Processing images across {num_gpus} GPUs in parallel...\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 5. Process images in batches across GPUs in parallel\n",
    "    batch_idx = 0\n",
    "    batch_num = 0\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=num_gpus) as executor:\n",
    "        while batch_idx < len(selected_images):\n",
    "            batch_num += 1\n",
    "            futures = []\n",
    "            \n",
    "            print(f\"\\nüîÑ Batch {batch_num}\")\n",
    "            \n",
    "            # Submit tasks for each GPU\n",
    "            for gpu_id in range(num_gpus):\n",
    "                start_idx = batch_idx + gpu_id * BATCH_SIZE\n",
    "                end_idx = min(start_idx + BATCH_SIZE, len(selected_images))\n",
    "                \n",
    "                if start_idx >= len(selected_images):\n",
    "                    break\n",
    "                \n",
    "                image_batch = selected_images[start_idx:end_idx]\n",
    "                \n",
    "                print(\n",
    "                    f\"   GPU {gpu_id}: Submitting {len(image_batch)} images \"\n",
    "                    f\"(indices {start_idx+1}-{end_idx})\"\n",
    "                )\n",
    "                \n",
    "                future = executor.submit(\n",
    "                    process_batch_on_gpu,\n",
    "                    models[gpu_id],\n",
    "                    image_batch,\n",
    "                    gpu_id,\n",
    "                    all_captions\n",
    "                )\n",
    "                futures.append(future)\n",
    "            \n",
    "            # Wait for all GPUs to complete this batch\n",
    "            for future in as_completed(futures):\n",
    "                num_captions, gpu_id = future.result()\n",
    "                print(f\"   ‚úÖ GPU {gpu_id}: Generated {num_captions} captions\")\n",
    "            \n",
    "            # Move to next batch (all GPUs combined)\n",
    "            batch_idx += num_gpus * BATCH_SIZE\n",
    "    \n",
    "    # 6. Save results\n",
    "    output_path = f\"{OUTPUT_DIR}/captions_missing_part_{NUM_ID}_of_{NUM_PARTS}.json\"\n",
    "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(all_captions, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"üìä FINAL SUMMARY (MISSING SUBSET)\")\n",
    "    print(f\"New part {NUM_ID}/{NUM_PARTS} (from original parts {MISSING_PARTS})\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"‚úÖ Saved captions: {output_path}\")\n",
    "    print(f\"üìä Total images processed: {len(selected_images)}\")\n",
    "    print(f\"üìä Total captions generated: {len(all_captions)}\")\n",
    "    print(f\"üìä Success rate: {len(all_captions)/len(selected_images)*100:.1f}%\")\n",
    "    print(\"‚úÖ All done!\")\n",
    "    \n",
    "    # 7. Cleanup\n",
    "    print(f\"\\nüßπ Cleaning up...\")\n",
    "    for gpu_id, model in enumerate(models):\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize(gpu_id)\n",
    "    gc.collect()\n",
    "    print(\"‚úÖ Cleanup complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c604b",
   "metadata": {
    "papermill": {
     "duration": 0.001416,
     "end_time": "2025-12-07T12:25:19.271658",
     "exception": false,
     "start_time": "2025-12-07T12:25:19.270242",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 8787551,
     "sourceId": 13801699,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8788127,
     "sourceId": 13802434,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 23.199062,
   "end_time": "2025-12-07T12:25:21.994243",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-07T12:24:58.795181",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

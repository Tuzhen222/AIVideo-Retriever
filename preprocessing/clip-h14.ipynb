{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfe45b99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T04:51:42.382358Z",
     "iopub.status.busy": "2025-12-01T04:51:42.381657Z",
     "iopub.status.idle": "2025-12-01T04:51:42.389240Z",
     "shell.execute_reply": "2025-12-01T04:51:42.388528Z"
    },
    "papermill": {
     "duration": 0.012934,
     "end_time": "2025-12-01T04:51:42.390670",
     "exception": false,
     "start_time": "2025-12-01T04:51:42.377736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "INDEX_FILE = \"/kaggle/input/irkeyframeindex/keyframe_index_kaggle.json\"\n",
    "NUM_PARTS = 12  # Total slices to divide the dataset\n",
    "PART_ID = 12    # 1-based slice id to execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "514709af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T04:51:42.396898Z",
     "iopub.status.busy": "2025-12-01T04:51:42.396693Z",
     "iopub.status.idle": "2025-12-01T04:53:01.819122Z",
     "shell.execute_reply": "2025-12-01T04:53:01.818142Z"
    },
    "papermill": {
     "duration": 79.426536,
     "end_time": "2025-12-01T04:53:01.820754",
     "exception": false,
     "start_time": "2025-12-01T04:51:42.394218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting open_clip_torch\r\n",
      "  Downloading open_clip_torch-3.2.0-py3-none-any.whl.metadata (32 kB)\r\n",
      "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2.6.0+cu124)\r\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.21.0+cu124)\r\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (2025.11.3)\r\n",
      "Collecting ftfy (from open_clip_torch)\r\n",
      "  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\r\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (4.67.1)\r\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.36.0)\r\n",
      "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (0.5.3)\r\n",
      "Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.11/dist-packages (from open_clip_torch) (1.0.19)\r\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.3)\r\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.20.0)\r\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (4.15.0)\r\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.5)\r\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\r\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2025.10.0)\r\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\r\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (0.6.2)\r\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (2.21.5)\r\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (12.4.127)\r\n",
      "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0->open_clip_torch)\r\n",
      "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\r\n",
      "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (3.2.0)\r\n",
      "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0->open_clip_torch) (1.13.1)\r\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0->open_clip_torch) (1.3.0)\r\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy->open_clip_torch) (0.2.13)\r\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\r\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (2.32.5)\r\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\r\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (1.26.4)\r\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->open_clip_torch) (11.3.0)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.3)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision->open_clip_torch) (2.4.1)\r\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.10.5)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision->open_clip_torch) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision->open_clip_torch) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision->open_clip_torch) (2024.2.0)\r\n",
      "Downloading open_clip_torch-3.2.0-py3-none-any.whl (1.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, open_clip_torch\r\n",
      "  Attempting uninstall: nvidia-nvjitlink-cu12\r\n",
      "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-curand-cu12\r\n",
      "    Found existing installation: nvidia-curand-cu12 10.3.6.82\r\n",
      "    Uninstalling nvidia-curand-cu12-10.3.6.82:\r\n",
      "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\r\n",
      "  Attempting uninstall: nvidia-cufft-cu12\r\n",
      "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\r\n",
      "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\r\n",
      "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\r\n",
      "  Attempting uninstall: nvidia-cuda-runtime-cu12\r\n",
      "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\r\n",
      "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cuda-cupti-cu12\r\n",
      "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\r\n",
      "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\r\n",
      "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\r\n",
      "  Attempting uninstall: nvidia-cublas-cu12\r\n",
      "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\r\n",
      "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\r\n",
      "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\r\n",
      "  Attempting uninstall: nvidia-cusparse-cu12\r\n",
      "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\r\n",
      "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\r\n",
      "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\r\n",
      "  Attempting uninstall: nvidia-cudnn-cu12\r\n",
      "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\r\n",
      "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\r\n",
      "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\r\n",
      "  Attempting uninstall: nvidia-cusolver-cu12\r\n",
      "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\r\n",
      "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\r\n",
      "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "libcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\r\n",
      "pylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed ftfy-6.3.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 open_clip_torch-3.2.0\r\n",
      "Collecting faiss-cpu\r\n",
      "  Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.7 kB)\r\n",
      "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (1.26.4)\r\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\r\n",
      "Requirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.3.8)\r\n",
      "Requirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (1.2.4)\r\n",
      "Requirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (0.1.1)\r\n",
      "Requirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\r\n",
      "Requirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\r\n",
      "Requirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<3.0,>=1.25.0->faiss-cpu) (2.4.1)\r\n",
      "Requirement already satisfied: onemkl-license==2025.3.0 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2025.3.0)\r\n",
      "Requirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Requirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2022.3.0)\r\n",
      "Requirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (1.4.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Requirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<3.0,>=1.25.0->faiss-cpu) (2024.2.0)\r\n",
      "Downloading faiss_cpu-1.13.0-cp39-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.6 MB)\r\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m95.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: faiss-cpu\r\n",
      "Successfully installed faiss-cpu-1.13.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install open_clip_torch\n",
    "!pip install faiss-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf64695b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T04:53:01.864404Z",
     "iopub.status.busy": "2025-12-01T04:53:01.864165Z",
     "iopub.status.idle": "2025-12-01T08:26:07.477490Z",
     "shell.execute_reply": "2025-12-01T08:26:07.476673Z"
    },
    "papermill": {
     "duration": 12785.637702,
     "end_time": "2025-12-01T08:26:07.479449",
     "exception": false,
     "start_time": "2025-12-01T04:53:01.841747",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Device: cuda\n",
      "ğŸ® GPU Count: 2\n",
      "   GPU 0: Tesla T4\n",
      "   GPU 1: Tesla T4\n",
      "\n",
      "ğŸ“š Total files in index: 702648\n",
      "ğŸ“¦ Selected slice [12/12]: 58554 files (rows 644094 -> 702647)\n",
      "\n",
      "ğŸ“Š GPU Assignment (files per GPU):\n",
      "   GPU 0: 29277 files\n",
      "   GPU 1: 29277 files\n",
      "ğŸ“¥ Loading CLIP model: ViT-H-14-378-quickgelu (dfn5b) on cuda:0\n",
      "ğŸ“¥ Loading CLIP model: ViT-H-14-378-quickgelu (dfn5b) on cuda:1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7321fb2da9842668e125657afd88b37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "open_clip_pytorch_model.bin:   0%|          | 0.00/3.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on cuda:0\n",
      "\n",
      "============================================================\n",
      "ğŸ“‚ Processing 29277 files on cuda:0 [GPU 0]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Embedding on cuda:0[GPU 0]:   0%|          | 0/229 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loaded on cuda:1\n",
      "\n",
      "============================================================\n",
      "ğŸ“‚ Processing 29277 files on cuda:1 [GPU 1]\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Embedding on cuda:0[GPU 0]:   0%|          | 1/229 [00:45<2:52:32, 45.41s/it]\n",
      "Embedding on cuda:0[GPU 0]:   1%|          | 2/229 [01:34<3:00:24, 47.68s/it]\n",
      "Embedding on cuda:0[GPU 0]:   1%|â–         | 3/229 [02:26<3:06:14, 49.45s/it]\n",
      "Embedding on cuda:0[GPU 0]:   2%|â–         | 5/229 [04:08<3:08:52, 50.59s/it]\n",
      "Embedding on cuda:0[GPU 0]:   3%|â–         | 6/229 [05:00<3:09:22, 50.95s/it]\n",
      "Embedding on cuda:0[GPU 0]:   3%|â–         | 7/229 [05:50<3:07:40, 50.72s/it]\n",
      "Embedding on cuda:0[GPU 0]:   3%|â–         | 8/229 [06:41<3:07:08, 50.81s/it]\n",
      "Embedding on cuda:0[GPU 0]:   4%|â–         | 9/229 [07:33<3:07:07, 51.03s/it]\n",
      "Embedding on cuda:0[GPU 0]:   4%|â–         | 10/229 [08:25<3:07:20, 51.33s/it]\n",
      "Embedding on cuda:0[GPU 0]:   5%|â–         | 11/229 [09:16<3:05:55, 51.17s/it]\n",
      "Embedding on cuda:0[GPU 0]:   5%|â–Œ         | 12/229 [10:07<3:04:58, 51.15s/it]\n",
      "Embedding on cuda:0[GPU 0]:   6%|â–Œ         | 13/229 [10:58<3:03:53, 51.08s/it]\n",
      "Embedding on cuda:0[GPU 0]:   6%|â–Œ         | 14/229 [11:49<3:03:19, 51.16s/it]\n",
      "Embedding on cuda:0[GPU 0]:   7%|â–‹         | 15/229 [12:40<3:02:35, 51.19s/it]\n",
      "Embedding on cuda:0[GPU 0]:   7%|â–‹         | 16/229 [13:32<3:01:59, 51.27s/it]\n",
      "Embedding on cuda:0[GPU 0]:   7%|â–‹         | 17/229 [14:22<3:00:23, 51.05s/it]\n",
      "Embedding on cuda:0[GPU 0]:   8%|â–Š         | 19/229 [16:05<2:59:45, 51.36s/it]\n",
      "Embedding on cuda:0[GPU 0]:   9%|â–Š         | 20/229 [16:56<2:57:47, 51.04s/it]\n",
      "Embedding on cuda:0[GPU 0]:   9%|â–‰         | 21/229 [17:46<2:56:39, 50.96s/it]\n",
      "Embedding on cuda:0[GPU 0]:  10%|â–‰         | 22/229 [18:38<2:56:53, 51.27s/it]\n",
      "Embedding on cuda:0[GPU 0]:  10%|â–ˆ         | 23/229 [19:30<2:56:36, 51.44s/it]\n",
      "Embedding on cuda:0[GPU 0]:  10%|â–ˆ         | 24/229 [20:22<2:56:28, 51.65s/it]\n",
      "Embedding on cuda:0[GPU 0]:  11%|â–ˆ         | 25/229 [21:14<2:56:06, 51.80s/it]\n",
      "Embedding on cuda:0[GPU 0]:  11%|â–ˆâ–        | 26/229 [22:06<2:54:49, 51.67s/it]\n",
      "Embedding on cuda:0[GPU 0]:  12%|â–ˆâ–        | 27/229 [22:57<2:53:23, 51.50s/it]\n",
      "Embedding on cuda:0[GPU 0]:  12%|â–ˆâ–        | 28/229 [23:48<2:52:02, 51.35s/it]\n",
      "Embedding on cuda:0[GPU 0]:  13%|â–ˆâ–        | 29/229 [24:40<2:51:50, 51.55s/it]\n",
      "Embedding on cuda:0[GPU 0]:  13%|â–ˆâ–        | 30/229 [25:31<2:50:27, 51.39s/it]\n",
      "Embedding on cuda:0[GPU 0]:  14%|â–ˆâ–        | 31/229 [26:23<2:49:45, 51.44s/it]\n",
      "Embedding on cuda:0[GPU 0]:  14%|â–ˆâ–        | 33/229 [28:05<2:47:54, 51.40s/it]\n",
      "Embedding on cuda:0[GPU 0]:  15%|â–ˆâ–        | 34/229 [28:56<2:46:34, 51.25s/it]\n",
      "Embedding on cuda:0[GPU 0]:  15%|â–ˆâ–Œ        | 35/229 [29:47<2:45:27, 51.17s/it]\n",
      "Embedding on cuda:0[GPU 0]:  16%|â–ˆâ–Œ        | 36/229 [30:38<2:44:22, 51.10s/it]\n",
      "Embedding on cuda:0[GPU 0]:  16%|â–ˆâ–Œ        | 37/229 [31:30<2:43:45, 51.18s/it]\n",
      "Embedding on cuda:0[GPU 0]:  17%|â–ˆâ–‹        | 38/229 [32:21<2:42:50, 51.15s/it]\n",
      "Embedding on cuda:0[GPU 0]:  17%|â–ˆâ–‹        | 39/229 [33:12<2:42:05, 51.19s/it]\n",
      "Embedding on cuda:0[GPU 0]:  17%|â–ˆâ–‹        | 40/229 [34:03<2:41:02, 51.12s/it]\n",
      "Embedding on cuda:0[GPU 0]:  18%|â–ˆâ–Š        | 41/229 [34:55<2:40:40, 51.28s/it]\n",
      "Embedding on cuda:0[GPU 0]:  18%|â–ˆâ–Š        | 42/229 [35:47<2:40:28, 51.49s/it]\n",
      "Embedding on cuda:0[GPU 0]:  19%|â–ˆâ–‰        | 43/229 [36:38<2:40:01, 51.62s/it]\n",
      "Embedding on cuda:0[GPU 0]:  19%|â–ˆâ–‰        | 44/229 [37:30<2:39:16, 51.66s/it]\n",
      "Embedding on cuda:0[GPU 0]:  20%|â–ˆâ–‰        | 45/229 [38:21<2:37:49, 51.47s/it]\n",
      "Embedding on cuda:0[GPU 0]:  21%|â–ˆâ–ˆ        | 47/229 [40:04<2:36:01, 51.44s/it]\n",
      "Embedding on cuda:0[GPU 0]:  21%|â–ˆâ–ˆ        | 48/229 [40:55<2:34:23, 51.18s/it]\n",
      "Embedding on cuda:0[GPU 0]:  21%|â–ˆâ–ˆâ–       | 49/229 [41:46<2:33:57, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  22%|â–ˆâ–ˆâ–       | 50/229 [42:38<2:33:13, 51.36s/it]\n",
      "Embedding on cuda:0[GPU 0]:  22%|â–ˆâ–ˆâ–       | 51/229 [43:29<2:32:00, 51.24s/it]\n",
      "Embedding on cuda:0[GPU 0]:  23%|â–ˆâ–ˆâ–       | 52/229 [44:20<2:30:44, 51.10s/it]\n",
      "Embedding on cuda:0[GPU 0]:  23%|â–ˆâ–ˆâ–       | 53/229 [45:10<2:29:11, 50.86s/it]\n",
      "Embedding on cuda:0[GPU 0]:  24%|â–ˆâ–ˆâ–       | 54/229 [46:01<2:28:35, 50.95s/it]\n",
      "Embedding on cuda:0[GPU 0]:  24%|â–ˆâ–ˆâ–       | 55/229 [46:52<2:28:09, 51.09s/it]\n",
      "Embedding on cuda:0[GPU 0]:  24%|â–ˆâ–ˆâ–       | 56/229 [47:43<2:27:07, 51.03s/it]\n",
      "Embedding on cuda:0[GPU 0]:  25%|â–ˆâ–ˆâ–       | 57/229 [48:35<2:26:35, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  25%|â–ˆâ–ˆâ–Œ       | 58/229 [49:26<2:26:13, 51.31s/it]\n",
      "Embedding on cuda:0[GPU 0]:  26%|â–ˆâ–ˆâ–Œ       | 60/229 [51:09<2:24:29, 51.30s/it]\n",
      "Embedding on cuda:0[GPU 0]:  27%|â–ˆâ–ˆâ–‹       | 61/229 [52:00<2:23:35, 51.28s/it]\n",
      "Embedding on cuda:0[GPU 0]:  27%|â–ˆâ–ˆâ–‹       | 62/229 [52:51<2:22:37, 51.24s/it]\n",
      "Embedding on cuda:0[GPU 0]:  28%|â–ˆâ–ˆâ–Š       | 63/229 [53:42<2:21:27, 51.13s/it]\n",
      "Embedding on cuda:0[GPU 0]:  28%|â–ˆâ–ˆâ–Š       | 64/229 [54:33<2:20:22, 51.04s/it]\n",
      "Embedding on cuda:0[GPU 0]:  28%|â–ˆâ–ˆâ–Š       | 65/229 [55:24<2:19:29, 51.04s/it]\n",
      "Embedding on cuda:0[GPU 0]:  29%|â–ˆâ–ˆâ–‰       | 66/229 [56:14<2:18:22, 50.94s/it]\n",
      "Embedding on cuda:0[GPU 0]:  29%|â–ˆâ–ˆâ–‰       | 67/229 [57:06<2:17:51, 51.06s/it]\n",
      "Embedding on cuda:0[GPU 0]:  30%|â–ˆâ–ˆâ–‰       | 68/229 [57:57<2:17:04, 51.09s/it]\n",
      "Embedding on cuda:0[GPU 0]:  30%|â–ˆâ–ˆâ–ˆ       | 69/229 [58:49<2:17:10, 51.44s/it]\n",
      "Embedding on cuda:0[GPU 0]:  31%|â–ˆâ–ˆâ–ˆ       | 70/229 [59:40<2:15:54, 51.29s/it]\n",
      "Embedding on cuda:0[GPU 0]:  31%|â–ˆâ–ˆâ–ˆ       | 71/229 [1:00:32<2:15:06, 51.30s/it]\n",
      "Embedding on cuda:0[GPU 0]:  31%|â–ˆâ–ˆâ–ˆâ–      | 72/229 [1:01:23<2:14:03, 51.23s/it]\n",
      "Embedding on cuda:0[GPU 0]:  32%|â–ˆâ–ˆâ–ˆâ–      | 74/229 [1:03:06<2:13:09, 51.55s/it]\n",
      "Embedding on cuda:0[GPU 0]:  33%|â–ˆâ–ˆâ–ˆâ–      | 75/229 [1:03:57<2:11:45, 51.34s/it]\n",
      "Embedding on cuda:0[GPU 0]:  33%|â–ˆâ–ˆâ–ˆâ–      | 76/229 [1:04:49<2:11:00, 51.38s/it]\n",
      "Embedding on cuda:0[GPU 0]:  34%|â–ˆâ–ˆâ–ˆâ–      | 77/229 [1:05:41<2:10:36, 51.56s/it]\n",
      "Embedding on cuda:0[GPU 0]:  34%|â–ˆâ–ˆâ–ˆâ–      | 78/229 [1:06:31<2:09:06, 51.30s/it]\n",
      "Embedding on cuda:0[GPU 0]:  34%|â–ˆâ–ˆâ–ˆâ–      | 79/229 [1:07:22<2:07:46, 51.11s/it]\n",
      "Embedding on cuda:0[GPU 0]:  35%|â–ˆâ–ˆâ–ˆâ–      | 80/229 [1:08:14<2:07:16, 51.25s/it]\n",
      "Embedding on cuda:0[GPU 0]:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 81/229 [1:09:06<2:07:04, 51.52s/it]\n",
      "Embedding on cuda:0[GPU 0]:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 82/229 [1:09:57<2:06:19, 51.56s/it]\n",
      "Embedding on cuda:0[GPU 0]:  36%|â–ˆâ–ˆâ–ˆâ–Œ      | 83/229 [1:10:49<2:05:16, 51.49s/it]\n",
      "Embedding on cuda:0[GPU 0]:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 84/229 [1:11:40<2:04:15, 51.42s/it]\n",
      "Embedding on cuda:0[GPU 0]:  37%|â–ˆâ–ˆâ–ˆâ–‹      | 85/229 [1:12:32<2:03:40, 51.53s/it]\n",
      "Embedding on cuda:0[GPU 0]:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 87/229 [1:14:15<2:01:45, 51.45s/it]\n",
      "Embedding on cuda:0[GPU 0]:  38%|â–ˆâ–ˆâ–ˆâ–Š      | 88/229 [1:15:06<2:00:51, 51.43s/it]\n",
      "Embedding on cuda:0[GPU 0]:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 89/229 [1:15:58<2:00:44, 51.74s/it]\n",
      "Embedding on cuda:0[GPU 0]:  39%|â–ˆâ–ˆâ–ˆâ–‰      | 90/229 [1:16:50<1:59:25, 51.55s/it]\n",
      "Embedding on cuda:0[GPU 0]:  40%|â–ˆâ–ˆâ–ˆâ–‰      | 91/229 [1:17:41<1:58:12, 51.40s/it]\n",
      "Embedding on cuda:0[GPU 0]:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 92/229 [1:18:31<1:56:58, 51.23s/it]\n",
      "Embedding on cuda:0[GPU 0]:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 93/229 [1:19:22<1:55:41, 51.04s/it]\n",
      "Embedding on cuda:0[GPU 0]:  41%|â–ˆâ–ˆâ–ˆâ–ˆ      | 94/229 [1:20:13<1:54:59, 51.11s/it]\n",
      "Embedding on cuda:0[GPU 0]:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 95/229 [1:21:04<1:54:10, 51.12s/it]\n",
      "Embedding on cuda:0[GPU 0]:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 96/229 [1:21:55<1:53:06, 51.03s/it]\n",
      "Embedding on cuda:0[GPU 0]:  42%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 97/229 [1:22:47<1:52:29, 51.13s/it]\n",
      "Embedding on cuda:0[GPU 0]:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 98/229 [1:23:38<1:51:35, 51.11s/it]\n",
      "Embedding on cuda:0[GPU 0]:  43%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 99/229 [1:24:30<1:51:16, 51.36s/it]\n",
      "Embedding on cuda:0[GPU 0]:  44%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 101/229 [1:26:13<1:49:53, 51.51s/it]\n",
      "Embedding on cuda:0[GPU 0]:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 102/229 [1:27:05<1:49:04, 51.53s/it]\n",
      "Embedding on cuda:0[GPU 0]:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–     | 103/229 [1:27:57<1:48:31, 51.68s/it]\n",
      "Embedding on cuda:0[GPU 0]:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 104/229 [1:28:48<1:47:34, 51.64s/it]\n",
      "Embedding on cuda:0[GPU 0]:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 105/229 [1:29:39<1:46:11, 51.39s/it]\n",
      "Embedding on cuda:0[GPU 0]:  46%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 106/229 [1:30:31<1:45:39, 51.54s/it]\n",
      "Embedding on cuda:0[GPU 0]:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 107/229 [1:31:21<1:44:02, 51.16s/it]\n",
      "Embedding on cuda:0[GPU 0]:  47%|â–ˆâ–ˆâ–ˆâ–ˆâ–‹     | 108/229 [1:32:12<1:43:08, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 109/229 [1:33:04<1:42:17, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 110/229 [1:33:55<1:41:31, 51.19s/it]\n",
      "Embedding on cuda:0[GPU 0]:  48%|â–ˆâ–ˆâ–ˆâ–ˆâ–Š     | 111/229 [1:34:47<1:41:25, 51.57s/it]\n",
      "Embedding on cuda:0[GPU 0]:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 112/229 [1:35:39<1:40:21, 51.47s/it]\n",
      "Embedding on cuda:0[GPU 0]:  49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 113/229 [1:36:30<1:39:16, 51.35s/it]\n",
      "Embedding on cuda:0[GPU 0]:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 115/229 [1:38:13<1:37:53, 51.53s/it]\n",
      "Embedding on cuda:0[GPU 0]:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 116/229 [1:39:04<1:36:44, 51.36s/it]\n",
      "Embedding on cuda:0[GPU 0]:  51%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 117/229 [1:39:55<1:36:01, 51.45s/it]\n",
      "Embedding on cuda:0[GPU 0]:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 118/229 [1:40:47<1:35:09, 51.43s/it]\n",
      "Embedding on cuda:0[GPU 0]:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 119/229 [1:41:39<1:34:24, 51.49s/it]\n",
      "Embedding on cuda:0[GPU 0]:  52%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 120/229 [1:42:29<1:33:14, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 121/229 [1:43:21<1:32:25, 51.35s/it]\n",
      "Embedding on cuda:0[GPU 0]:  53%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 122/229 [1:44:12<1:31:32, 51.33s/it]\n",
      "Embedding on cuda:0[GPU 0]:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 123/229 [1:45:03<1:30:36, 51.29s/it]\n",
      "Embedding on cuda:0[GPU 0]:  54%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 124/229 [1:45:55<1:29:49, 51.33s/it]\n",
      "Embedding on cuda:0[GPU 0]:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–    | 125/229 [1:46:47<1:29:13, 51.48s/it]\n",
      "Embedding on cuda:0[GPU 0]:  55%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 126/229 [1:47:38<1:28:07, 51.33s/it]\n",
      "Embedding on cuda:0[GPU 0]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ    | 128/229 [1:49:20<1:26:08, 51.17s/it]\n",
      "Embedding on cuda:0[GPU 0]:  56%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 129/229 [1:50:11<1:25:27, 51.27s/it]\n",
      "Embedding on cuda:0[GPU 0]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 130/229 [1:51:02<1:24:09, 51.01s/it]\n",
      "Embedding on cuda:0[GPU 0]:  57%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹    | 131/229 [1:51:53<1:23:23, 51.06s/it]\n",
      "Embedding on cuda:0[GPU 0]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 132/229 [1:52:43<1:22:17, 50.90s/it]\n",
      "Embedding on cuda:0[GPU 0]:  58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 133/229 [1:53:35<1:21:41, 51.06s/it]\n",
      "Embedding on cuda:0[GPU 0]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š    | 134/229 [1:54:27<1:21:12, 51.29s/it]\n",
      "Embedding on cuda:0[GPU 0]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 135/229 [1:55:18<1:20:14, 51.22s/it]\n",
      "Embedding on cuda:0[GPU 0]:  59%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 136/229 [1:56:08<1:18:55, 50.91s/it]\n",
      "Embedding on cuda:0[GPU 0]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰    | 137/229 [1:56:59<1:18:14, 51.03s/it]\n",
      "Embedding on cuda:0[GPU 0]:  60%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 138/229 [1:57:51<1:17:40, 51.21s/it]\n",
      "Embedding on cuda:0[GPU 0]:  61%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ    | 139/229 [1:58:41<1:16:30, 51.01s/it]\n",
      "Embedding on cuda:0[GPU 0]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 141/229 [2:00:25<1:15:22, 51.39s/it]\n",
      "Embedding on cuda:0[GPU 0]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 142/229 [2:01:16<1:14:35, 51.44s/it]\n",
      "Embedding on cuda:0[GPU 0]:  62%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 143/229 [2:02:07<1:13:26, 51.24s/it]\n",
      "Embedding on cuda:0[GPU 0]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 144/229 [2:02:59<1:12:40, 51.30s/it]\n",
      "Embedding on cuda:0[GPU 0]:  63%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 145/229 [2:03:50<1:11:47, 51.29s/it]\n",
      "Embedding on cuda:0[GPU 0]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 146/229 [2:04:41<1:11:04, 51.37s/it]\n",
      "Embedding on cuda:0[GPU 0]:  64%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 147/229 [2:05:32<1:09:48, 51.08s/it]\n",
      "Embedding on cuda:0[GPU 0]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–   | 148/229 [2:06:23<1:09:02, 51.15s/it]\n",
      "Embedding on cuda:0[GPU 0]:  65%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 149/229 [2:07:14<1:08:16, 51.20s/it]\n",
      "Embedding on cuda:0[GPU 0]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 150/229 [2:08:06<1:07:34, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ   | 151/229 [2:08:58<1:06:53, 51.45s/it]\n",
      "Embedding on cuda:0[GPU 0]:  66%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 152/229 [2:09:48<1:05:42, 51.20s/it]\n",
      "Embedding on cuda:0[GPU 0]:  67%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹   | 154/229 [2:11:31<1:03:54, 51.12s/it]\n",
      "Embedding on cuda:0[GPU 0]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 155/229 [2:12:22<1:03:15, 51.28s/it]\n",
      "Embedding on cuda:0[GPU 0]:  68%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 156/229 [2:13:14<1:02:24, 51.29s/it]\n",
      "Embedding on cuda:0[GPU 0]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š   | 157/229 [2:14:04<1:01:19, 51.11s/it]\n",
      "Embedding on cuda:0[GPU 0]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 158/229 [2:14:55<1:00:30, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  69%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 159/229 [2:15:47<59:51, 51.31s/it]  \n",
      "Embedding on cuda:0[GPU 0]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰   | 160/229 [2:16:38<58:45, 51.10s/it]\n",
      "Embedding on cuda:0[GPU 0]:  70%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 161/229 [2:17:29<57:57, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 162/229 [2:18:20<57:12, 51.24s/it]\n",
      "Embedding on cuda:0[GPU 0]:  71%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ   | 163/229 [2:19:12<56:26, 51.31s/it]\n",
      "Embedding on cuda:0[GPU 0]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 164/229 [2:20:03<55:27, 51.20s/it]\n",
      "Embedding on cuda:0[GPU 0]:  72%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 165/229 [2:20:55<54:49, 51.40s/it]\n",
      "Embedding on cuda:0[GPU 0]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 167/229 [2:22:37<53:05, 51.38s/it]\n",
      "Embedding on cuda:0[GPU 0]:  73%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 168/229 [2:23:28<52:07, 51.27s/it]\n",
      "Embedding on cuda:0[GPU 0]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 169/229 [2:24:19<51:08, 51.14s/it]\n",
      "Embedding on cuda:0[GPU 0]:  74%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 170/229 [2:25:11<50:29, 51.34s/it]\n",
      "Embedding on cuda:0[GPU 0]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–  | 171/229 [2:26:03<49:44, 51.46s/it]\n",
      "Embedding on cuda:0[GPU 0]:  75%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 172/229 [2:26:54<48:57, 51.53s/it]\n",
      "Embedding on cuda:0[GPU 0]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 173/229 [2:27:45<47:57, 51.39s/it]\n",
      "Embedding on cuda:0[GPU 0]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ  | 174/229 [2:28:37<47:07, 51.41s/it]\n",
      "Embedding on cuda:0[GPU 0]:  76%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 175/229 [2:29:29<46:24, 51.56s/it]\n",
      "Embedding on cuda:0[GPU 0]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 176/229 [2:30:20<45:19, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  77%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹  | 177/229 [2:31:11<44:23, 51.22s/it]\n",
      "Embedding on cuda:0[GPU 0]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 178/229 [2:32:01<43:27, 51.12s/it]\n",
      "Embedding on cuda:0[GPU 0]:  78%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š  | 179/229 [2:32:53<42:45, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 181/229 [2:34:36<41:03, 51.32s/it]\n",
      "Embedding on cuda:0[GPU 0]:  79%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 182/229 [2:35:27<40:06, 51.20s/it]\n",
      "Embedding on cuda:0[GPU 0]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰  | 183/229 [2:36:18<39:13, 51.16s/it]\n",
      "Embedding on cuda:0[GPU 0]:  80%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 184/229 [2:37:09<38:20, 51.13s/it]\n",
      "Embedding on cuda:0[GPU 0]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 185/229 [2:38:00<37:35, 51.26s/it]\n",
      "Embedding on cuda:0[GPU 0]:  81%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ  | 186/229 [2:38:51<36:39, 51.16s/it]\n",
      "Embedding on cuda:0[GPU 0]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 187/229 [2:39:43<35:56, 51.35s/it]\n",
      "Embedding on cuda:0[GPU 0]:  82%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 188/229 [2:40:34<35:02, 51.28s/it]\n",
      "Embedding on cuda:0[GPU 0]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 189/229 [2:41:26<34:10, 51.27s/it]\n",
      "Embedding on cuda:0[GPU 0]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 190/229 [2:42:17<33:25, 51.43s/it]\n",
      "Embedding on cuda:0[GPU 0]:  83%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 191/229 [2:43:08<32:26, 51.24s/it]\n",
      "Embedding on cuda:0[GPU 0]:  84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 193/229 [2:44:50<30:42, 51.18s/it]\n",
      "Embedding on cuda:0[GPU 0]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 194/229 [2:45:41<29:45, 51.02s/it]\n",
      "Embedding on cuda:0[GPU 0]:  85%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 195/229 [2:46:32<28:54, 51.03s/it]\n",
      "Embedding on cuda:0[GPU 0]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 196/229 [2:47:23<28:06, 51.10s/it]\n",
      "Embedding on cuda:0[GPU 0]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ | 197/229 [2:48:15<27:15, 51.10s/it]\n",
      "Embedding on cuda:0[GPU 0]:  86%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 198/229 [2:49:06<26:27, 51.19s/it]\n",
      "Embedding on cuda:0[GPU 0]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 199/229 [2:49:57<25:32, 51.07s/it]\n",
      "Embedding on cuda:0[GPU 0]:  87%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹ | 200/229 [2:50:48<24:43, 51.15s/it]\n",
      "Embedding on cuda:0[GPU 0]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 201/229 [2:51:40<23:55, 51.25s/it]\n",
      "Embedding on cuda:0[GPU 0]:  88%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 202/229 [2:52:30<23:01, 51.15s/it]\n",
      "Embedding on cuda:0[GPU 0]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š | 203/229 [2:53:22<22:11, 51.19s/it]\n",
      "Embedding on cuda:0[GPU 0]:  89%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 204/229 [2:54:14<21:27, 51.49s/it]\n",
      "Embedding on cuda:0[GPU 0]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰ | 205/229 [2:55:07<20:46, 51.95s/it]\n",
      "Embedding on cuda:0[GPU 0]:  90%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 207/229 [2:56:49<18:51, 51.42s/it]\n",
      "Embedding on cuda:0[GPU 0]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ | 208/229 [2:57:39<17:55, 51.21s/it]\n",
      "Embedding on cuda:0[GPU 0]:  91%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 209/229 [2:58:31<17:07, 51.40s/it]\n",
      "Embedding on cuda:0[GPU 0]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 210/229 [2:59:23<16:17, 51.43s/it]\n",
      "Embedding on cuda:0[GPU 0]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 211/229 [3:00:14<15:26, 51.45s/it]\n",
      "Embedding on cuda:0[GPU 0]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 212/229 [3:01:05<14:33, 51.40s/it]\n",
      "Embedding on cuda:0[GPU 0]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 213/229 [3:01:57<13:42, 51.41s/it]\n",
      "Embedding on cuda:0[GPU 0]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 214/229 [3:02:49<12:54, 51.66s/it]\n",
      "Embedding on cuda:0[GPU 0]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 215/229 [3:03:41<12:02, 51.60s/it]\n",
      "Embedding on cuda:0[GPU 0]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 216/229 [3:04:32<11:09, 51.47s/it]\n",
      "Embedding on cuda:0[GPU 0]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217/229 [3:05:24<10:21, 51.78s/it]\n",
      "Embedding on cuda:0[GPU 0]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 218/229 [3:06:16<09:29, 51.77s/it]\n",
      "Embedding on cuda:0[GPU 0]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 219/229 [3:07:08<08:37, 51.77s/it]\n",
      "Embedding on cuda:0[GPU 0]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 221/229 [3:08:51<06:52, 51.59s/it]\n",
      "Embedding on cuda:0[GPU 0]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 222/229 [3:09:42<06:01, 51.59s/it]\n",
      "Embedding on cuda:0[GPU 0]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 223/229 [3:10:33<05:08, 51.34s/it]\n",
      "Embedding on cuda:0[GPU 0]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 224/229 [3:11:25<04:17, 51.48s/it]\n",
      "Embedding on cuda:0[GPU 0]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 225/229 [3:12:17<03:26, 51.67s/it]\n",
      "Embedding on cuda:0[GPU 0]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 226/229 [3:13:08<02:34, 51.49s/it]\n",
      "Embedding on cuda:0[GPU 0]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 227/229 [3:13:58<01:42, 51.16s/it]\n",
      "Embedding on cuda:0[GPU 0]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [3:15:22<00:00, 51.19s/it]\n",
      "\n",
      "Embedding on cuda:1[GPU 1]:  92%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 211/229 [3:15:22<16:38, 55.45s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 212/229 [3:16:20<15:51, 56.00s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 213/229 [3:17:17<15:01, 56.32s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  93%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 214/229 [3:18:14<14:08, 56.59s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 215/229 [3:19:11<13:15, 56.85s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  94%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 216/229 [3:20:08<12:19, 56.90s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–| 217/229 [3:21:05<11:23, 56.93s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  95%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 218/229 [3:22:02<10:26, 56.98s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 219/229 [3:22:59<09:29, 56.98s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  96%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Œ| 220/229 [3:23:57<08:33, 57.01s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 221/229 [3:24:53<07:35, 56.99s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 222/229 [3:25:51<06:39, 57.03s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  97%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‹| 223/229 [3:26:48<05:42, 57.10s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 224/229 [3:27:45<04:45, 57.14s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  98%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 225/229 [3:28:42<03:48, 57.13s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š| 226/229 [3:29:40<02:51, 57.22s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]:  99%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 227/229 [3:30:37<01:54, 57.22s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‰| 228/229 [3:31:34<00:57, 57.24s/it]\u001b[A\n",
      "Embedding on cuda:1[GPU 1]: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 229/229 [3:32:09<00:00, 55.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ… Saved FAISS index: /kaggle/working/immich_vith14_378_dfn5b_part12.bin\n",
      "âœ… Saved mapping: /kaggle/working/immich_vith14_378_dfn5b_part12_mapping.json\n",
      "ğŸ“Š Total vectors: 58554, Dimension: 1024\n",
      "\n",
      "============================================================\n",
      "ğŸ“Š WORKER SUMMARY\n",
      "============================================================\n",
      "  Worker 0: 29277 files -> OK\n",
      "  Worker 1: 29277 files -> OK\n",
      "============================================================\n",
      "\n",
      "âœ… ALL DONE!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import faiss\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import open_clip\n",
    "from torchvision import transforms\n",
    "from natsort import natsorted\n",
    "import gc\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import threading\n",
    "import math\n",
    "\n",
    "# ========= CONFIG =========\n",
    "MODEL_TAG = \"immich_vith14_378_dfn5b\"\n",
    "MODEL_NAME = \"ViT-H-14-378-quickgelu\"\n",
    "PRETRAINED = \"dfn5b\"\n",
    "\n",
    "KEYFRAME_ROOT = \"/kaggle/input/batch1/keyframes\"\n",
    "OUTPUT_DIR = \"/kaggle/working\"\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "USE_MULTI_GPU = True  # Enable multi-GPU processing\n",
    "\n",
    "INDEX_FILE = globals().get(\"INDEX_FILE\", \"/kaggle/input/keyframe-index/keyframe_index_kaggle.json\")\n",
    "NUM_PARTS = int(globals().get(\"NUM_PARTS\", 1))\n",
    "PART_ID = int(globals().get(\"PART_ID\", 1))\n",
    "\n",
    "# ========= MODEL LOADING =========\n",
    "def load_clip_model(device=None):\n",
    "    \"\"\"Load CLIP model from immich on specific device\"\"\"\n",
    "    if device is None:\n",
    "        device = DEVICE\n",
    "    print(f\"ğŸ“¥ Loading CLIP model: {MODEL_NAME} ({PRETRAINED}) on {device}\")\n",
    "    model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "        MODEL_NAME,\n",
    "        pretrained=PRETRAINED,\n",
    "        device=device\n",
    "    )\n",
    "    model = model.to(device).eval()\n",
    "    print(f\"âœ… Model loaded on {device}\")\n",
    "    return model, preprocess\n",
    "\n",
    "# ========= TRANSFORM =========\n",
    "def create_transform():\n",
    "    \"\"\"Create image transform pipeline\"\"\"\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((378, 378)),\n",
    "        transforms.CenterCrop(378),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )\n",
    "    ])\n",
    "\n",
    "# ========= EMBEDDING =========\n",
    "@torch.inference_mode()\n",
    "def extract_embeddings_batch(image_paths, model, transform, device):\n",
    "    \"\"\"Extract embeddings for a batch of images\"\"\"\n",
    "    images = []\n",
    "    for img_path in image_paths:\n",
    "        try:\n",
    "            img = Image.open(img_path).convert(\"RGB\")\n",
    "            img_tensor = transform(img)\n",
    "            images.append(img_tensor)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Error loading {img_path}: {e}\")\n",
    "            # Use zero tensor as placeholder\n",
    "            images.append(torch.zeros(3, 378, 378))\n",
    "    \n",
    "    if not images:\n",
    "        return None\n",
    "    \n",
    "    batch = torch.stack(images).to(device)\n",
    "    \n",
    "    # Extract visual features\n",
    "    features = model.encode_image(batch)\n",
    "    \n",
    "    # Normalize features\n",
    "    features = F.normalize(features, dim=-1)\n",
    "    \n",
    "    return features.cpu().numpy()\n",
    "\n",
    "# ========= DATASET HELPERS =========\n",
    "def load_index_file(index_path):\n",
    "    if not os.path.exists(index_path):\n",
    "        raise FileNotFoundError(f\"Index file not found: {index_path}\")\n",
    "    with open(index_path, \"r\") as f:\n",
    "        data = json.load(f)\n",
    "    if isinstance(data, dict):\n",
    "        try:\n",
    "            items = sorted(data.items(), key=lambda kv: int(kv[0]))\n",
    "        except ValueError:\n",
    "            items = sorted(data.items(), key=lambda kv: kv[0])\n",
    "        paths = [v for _, v in items]\n",
    "    elif isinstance(data, list):\n",
    "        paths = data\n",
    "    else:\n",
    "        raise ValueError(\"Index file must be a list or dict\")\n",
    "    cleaned = [p.strip() for p in paths if p]\n",
    "    if not cleaned:\n",
    "        raise ValueError(\"Index file is empty\")\n",
    "    return cleaned\n",
    "\n",
    "def select_dataset_slice(all_paths, num_parts, part_id):\n",
    "    if num_parts < 1:\n",
    "        raise ValueError(\"NUM_PARTS must be >= 1\")\n",
    "    if part_id < 1 or part_id > num_parts:\n",
    "        raise ValueError(\"PART_ID must be within [1, NUM_PARTS]\")\n",
    "    chunk_size = math.ceil(len(all_paths) / num_parts)\n",
    "    start = (part_id - 1) * chunk_size\n",
    "    end = min(start + chunk_size, len(all_paths))\n",
    "    return all_paths[start:end], start, end\n",
    "\n",
    "def chunk_paths(paths, num_chunks):\n",
    "    if num_chunks <= 1 or not paths:\n",
    "        return [paths]\n",
    "    chunk_size = math.ceil(len(paths) / num_chunks)\n",
    "    return [paths[i:i + chunk_size] for i in range(0, len(paths), chunk_size)]\n",
    "\n",
    "def resolve_image_path(path_str):\n",
    "    candidate = Path(path_str)\n",
    "    if candidate.exists():\n",
    "        return candidate\n",
    "    fallback = Path(KEYFRAME_ROOT) / path_str\n",
    "    if fallback.exists():\n",
    "        return fallback\n",
    "    return candidate\n",
    "\n",
    "@torch.inference_mode()\n",
    "def process_path_chunk(image_paths, model, transform, device, label=\"\"):\n",
    "    if not image_paths:\n",
    "        return None, []\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"ğŸ“‚ Processing {len(image_paths)} files on {device} {label}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    embeddings, ordered_paths = [], []\n",
    "    for i in tqdm(range(0, len(image_paths), BATCH_SIZE), desc=f\"Embedding on {device}{label}\"):\n",
    "        batch_raw = image_paths[i:i+BATCH_SIZE]\n",
    "        batch_files = [resolve_image_path(p) for p in batch_raw]\n",
    "        batch_emb = extract_embeddings_batch(batch_files, model, transform, device)\n",
    "        if batch_emb is not None:\n",
    "            embeddings.append(batch_emb)\n",
    "            ordered_paths.extend(str(p).replace('\\\\', '/') for p in batch_files)\n",
    "    if not embeddings:\n",
    "        return None, []\n",
    "    emb_array = np.vstack(embeddings).astype(\"float32\")\n",
    "    emb_array = emb_array / np.linalg.norm(emb_array, axis=1, keepdims=True)\n",
    "    return emb_array, ordered_paths\n",
    "\n",
    "# ========= PROCESS WITH GPU =========\n",
    "def process_with_gpu(image_paths, gpu_id):\n",
    "    device = f\"cuda:{gpu_id}\"\n",
    "    try:\n",
    "        model, _ = load_clip_model(device=device)\n",
    "        transform = create_transform()\n",
    "        emb_array, resolved_paths = process_path_chunk(image_paths, model, transform, device, label=f\"[GPU {gpu_id}]\")\n",
    "        del model\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.synchronize()\n",
    "        return {\n",
    "            'gpu': gpu_id,\n",
    "            'embeddings': emb_array,\n",
    "            'paths': resolved_paths,\n",
    "            'count': len(resolved_paths)\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error processing chunk on GPU {gpu_id}: {e}\")\n",
    "        return {\n",
    "            'gpu': gpu_id,\n",
    "            'embeddings': None,\n",
    "            'paths': [],\n",
    "            'count': 0,\n",
    "            'error': str(e)\n",
    "        }\n",
    "\n",
    "# ========= MAIN =========\n",
    "def main():\n",
    "    print(f\"ğŸ”§ Device: {DEVICE}\")\n",
    "    num_gpus = torch.cuda.device_count() if torch.cuda.is_available() else 0\n",
    "    if num_gpus:\n",
    "        print(f\"ğŸ® GPU Count: {num_gpus}\")\n",
    "        for i in range(num_gpus):\n",
    "            print(f\"   GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "\n",
    "    all_paths = load_index_file(INDEX_FILE)\n",
    "    target_paths, slice_start, slice_end = select_dataset_slice(all_paths, NUM_PARTS, PART_ID)\n",
    "    print(f\"\\nğŸ“š Total files in index: {len(all_paths)}\")\n",
    "    print(f\"ğŸ“¦ Selected slice [{PART_ID}/{NUM_PARTS}]: {len(target_paths)} files (rows {slice_start} -> {max(slice_end - 1, slice_start)})\")\n",
    "    if not target_paths:\n",
    "        print(\"âš ï¸ Nothing to process in this slice\")\n",
    "        return\n",
    "\n",
    "    use_parallel = USE_MULTI_GPU and num_gpus > 1\n",
    "    combined_embeddings, combined_paths, worker_reports = [], [], []\n",
    "\n",
    "    if use_parallel:\n",
    "        path_chunks = chunk_paths(target_paths, num_gpus)\n",
    "        assignment = {i: 0 for i in range(num_gpus)}\n",
    "        for idx, chunk in enumerate(path_chunks):\n",
    "            assignment[idx % num_gpus] += len(chunk)\n",
    "        print(\"\\nğŸ“Š GPU Assignment (files per GPU):\")\n",
    "        for gpu_id, count in assignment.items():\n",
    "            print(f\"   GPU {gpu_id}: {count} files\")\n",
    "        with ThreadPoolExecutor(max_workers=min(num_gpus, len(path_chunks))) as executor:\n",
    "            futures = []\n",
    "            for idx, chunk in enumerate(path_chunks):\n",
    "                if not chunk:\n",
    "                    continue\n",
    "                gpu_id = idx % num_gpus\n",
    "                futures.append(executor.submit(process_with_gpu, chunk, gpu_id))\n",
    "            for future in futures:\n",
    "                result = future.result()\n",
    "                worker_reports.append(result)\n",
    "                if result.get('embeddings') is not None:\n",
    "                    combined_embeddings.append(result['embeddings'])\n",
    "                    combined_paths.extend(result['paths'])\n",
    "    else:\n",
    "        device = DEVICE\n",
    "        model, _ = load_clip_model(device=device)\n",
    "        transform = create_transform()\n",
    "        emb_array, resolved_paths = process_path_chunk(target_paths, model, transform, device)\n",
    "        worker_reports.append({\n",
    "            'gpu': 0 if device.startswith('cuda') else 'cpu',\n",
    "            'embeddings': emb_array,\n",
    "            'paths': resolved_paths,\n",
    "            'count': len(resolved_paths)\n",
    "        })\n",
    "        if emb_array is not None:\n",
    "            combined_embeddings.append(emb_array)\n",
    "            combined_paths.extend(resolved_paths)\n",
    "        del model\n",
    "        cleanup_gpu()\n",
    "\n",
    "    combined_embeddings = [emb for emb in combined_embeddings if emb is not None]\n",
    "    if not combined_embeddings:\n",
    "        print(\"âŒ No embeddings were produced. Aborting.\")\n",
    "        return\n",
    "\n",
    "    emb_matrix = np.vstack(combined_embeddings).astype(\"float32\")\n",
    "    mapping = {str(i): path for i, path in enumerate(combined_paths)}\n",
    "    dimension = emb_matrix.shape[1]\n",
    "    index = faiss.IndexFlatIP(dimension)\n",
    "    index.add(emb_matrix)\n",
    "\n",
    "    part_suffix = f\"part{PART_ID:02d}\"\n",
    "    output_index = Path(OUTPUT_DIR) / f\"{MODEL_TAG}_{part_suffix}.bin\"\n",
    "    output_mapping = Path(OUTPUT_DIR) / f\"{MODEL_TAG}_{part_suffix}_mapping.json\"\n",
    "    faiss.write_index(index, str(output_index))\n",
    "    with open(output_mapping, \"w\") as f:\n",
    "        json.dump(mapping, f, indent=2)\n",
    "\n",
    "    print(f\"\\nâœ… Saved FAISS index: {output_index}\")\n",
    "    print(f\"âœ… Saved mapping: {output_mapping}\")\n",
    "    print(f\"ğŸ“Š Total vectors: {emb_matrix.shape[0]}, Dimension: {dimension}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ğŸ“Š WORKER SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    for report in worker_reports:\n",
    "        gpu_label = report.get('gpu', 'cpu')\n",
    "        count = report.get('count', 0)\n",
    "        status = \"OK\" if report.get('embeddings') is not None else f\"FAILED ({report.get('error', 'unknown error')})\"\n",
    "        print(f\"  Worker {gpu_label}: {count} files -> {status}\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nâœ… ALL DONE!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "659e1fb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T08:26:07.611551Z",
     "iopub.status.busy": "2025-12-01T08:26:07.610863Z",
     "iopub.status.idle": "2025-12-01T08:26:21.100265Z",
     "shell.execute_reply": "2025-12-01T08:26:21.099654Z"
    },
    "papermill": {
     "duration": 13.548196,
     "end_time": "2025-12-01T08:26:21.101712",
     "exception": false,
     "start_time": "2025-12-01T08:26:07.553516",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import faiss\n",
    "import numpy as np\n",
    "import open_clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "output_suffix = f\"part{globals().get('PART_ID', 1):02d}\"\n",
    "index_path = Path(\"/kaggle/working\") / f\"{MODEL_TAG}_{output_suffix}.bin\"\n",
    "mapping_path = Path(\"/kaggle/working\") / f\"{MODEL_TAG}_{output_suffix}_mapping.json\"\n",
    "index = faiss.read_index(str(index_path))\n",
    "with open(mapping_path, \"r\") as f:\n",
    "    index_mapping = json.load(f)\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms(\n",
    "    \"ViT-H-14-378-quickgelu\", pretrained=\"dfn5b\"\n",
    ")\n",
    "tokenizer = open_clip.get_tokenizer(\"ViT-H-14-378-quickgelu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59e2b98b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-01T08:26:21.216621Z",
     "iopub.status.busy": "2025-12-01T08:26:21.215927Z",
     "iopub.status.idle": "2025-12-01T08:26:21.724123Z",
     "shell.execute_reply": "2025-12-01T08:26:21.723433Z"
    },
    "papermill": {
     "duration": 0.566227,
     "end_time": "2025-12-01T08:26:21.725318",
     "exception": false,
     "start_time": "2025-12-01T08:26:21.159091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Top results:\n",
      "Idx = 28848, Cosine = 0.3228, Path = /kaggle/input/irkeyframe/keyframes/L22/L22_V026/24648.webp\n",
      "Idx = 28847, Cosine = 0.3205, Path = /kaggle/input/irkeyframe/keyframes/L22/L22_V026/24608.webp\n",
      "Idx = 28911, Cosine = 0.3205, Path = /kaggle/input/irkeyframe/keyframes/L22/L22_V026/26845.webp\n",
      "Idx = 28912, Cosine = 0.3198, Path = /kaggle/input/irkeyframe/keyframes/L22/L22_V026/26885.webp\n",
      "Idx = 28846, Cosine = 0.3197, Path = /kaggle/input/irkeyframe/keyframes/L22/L22_V026/24568.webp\n"
     ]
    }
   ],
   "source": [
    "# Text query\n",
    "text = \"a man wear a green shirt and red hat in the head\"\n",
    "tok = tokenizer([text])\n",
    "\n",
    "with torch.no_grad():\n",
    "    t = model.encode_text(tok)\n",
    "    t = F.normalize(t, dim=-1).cpu().numpy()\n",
    "\n",
    "# Search\n",
    "k = 5\n",
    "D, I = index.search(t, k)\n",
    "\n",
    "print(\"\\nğŸ” Top results:\")\n",
    "for score, idx in zip(D[0], I[0]):\n",
    "    path = index_mapping.get(str(idx), \"<missing>\")\n",
    "    print(f\"Idx = {idx}, Cosine = {score:.4f}, Path = {path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85f439",
   "metadata": {
    "papermill": {
     "duration": 0.055781,
     "end_time": "2025-12-01T08:26:21.838463",
     "exception": false,
     "start_time": "2025-12-01T08:26:21.782682",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8787551,
     "sourceId": 13801699,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 8788127,
     "sourceId": 13802434,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 12887.068605,
   "end_time": "2025-12-01T08:26:25.720042",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-01T04:51:38.651437",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "287f3ad4bd574150a0cb80df5dbde79b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8d82789aed7a41c19c806d8c3c799340",
       "max": 3947081637.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3c6fb45318ab47eab9fa69a285a1d7b4",
       "tabbable": null,
       "tooltip": null,
       "value": 3947081637.0
      }
     },
     "3c6fb45318ab47eab9fa69a285a1d7b4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "8d82789aed7a41c19c806d8c3c799340": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "b4311bcb12f84ed0a6d3146900a8cee9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "cd6f13eb2ff145bdbf7f74f45bf5dfce": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ea55e81851e94695998dce4c6cf0ebfa",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_d532fb1a11fc47f2a3620f477f38bfc0",
       "tabbable": null,
       "tooltip": null,
       "value": "open_clip_pytorch_model.bin:â€‡100%"
      }
     },
     "d2b31a9edad24efbb919a3e74d385b0e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "d532fb1a11fc47f2a3620f477f38bfc0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "d7321fb2da9842668e125657afd88b37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_cd6f13eb2ff145bdbf7f74f45bf5dfce",
        "IPY_MODEL_287f3ad4bd574150a0cb80df5dbde79b",
        "IPY_MODEL_de394f2d14ac4b1f8dd8a5a61351d5aa"
       ],
       "layout": "IPY_MODEL_d2b31a9edad24efbb919a3e74d385b0e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "de394f2d14ac4b1f8dd8a5a61351d5aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_f3360040e4b54390b54812877cae52aa",
       "placeholder": "â€‹",
       "style": "IPY_MODEL_b4311bcb12f84ed0a6d3146900a8cee9",
       "tabbable": null,
       "tooltip": null,
       "value": "â€‡3.95G/3.95Gâ€‡[00:10&lt;00:00,â€‡914MB/s]"
      }
     },
     "ea55e81851e94695998dce4c6cf0ebfa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3360040e4b54390b54812877cae52aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
